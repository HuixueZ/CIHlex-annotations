{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh_SHNLZkCQf",
        "outputId": "0d17d980-d688-4f58-d78a-464687077f91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SELECTED_ANNOTATOR=['Nathan','Huixue']"
      ],
      "metadata": {
        "id": "bB_P81j0i9Nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crgQV6kYfMLL"
      },
      "outputs": [],
      "source": [
        "DIR_PATH='/content/drive/MyDrive/CAM_NER_RE_files/p2175_CAM_Gene_v5'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SELECT_ABSTRACTS=['10072988','10172712','10380449','11191042','11301211',\n",
        "                  '11677409','11986575','12434945','12584510','12799612',\n",
        "                  '12828853','12853717','14521273','14605483','15039508',\n",
        "                  '15354371','15804591','15845676','16078356','16388436',\n",
        "                  '16459202','16528927','16643478','16679985','16715021']"
      ],
      "metadata": {
        "id": "4Gtdm77PmANl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xmltodict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVGzcGf1kn4k",
        "outputId": "1b2b34a7-a5c5-4805-d08c-a6da9e5d62f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: xmltodict\n",
            "Successfully installed xmltodict-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from abc import ABC, abstractmethod\n",
        "import xmltodict\n",
        "import os\n",
        "import json\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "S78Wa1-SkHmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interested_tags2=[]\n",
        "\n",
        "class AnnotationsExtraction(ABC):\n",
        "  DATA_SET_DIR=''\n",
        "\n",
        "  def __init__(self, file_path):\n",
        "    self.file_path=file_path\n",
        "\n",
        "  def get_text(self):\n",
        "    file = open(self.file_path, 'r', encoding='utf-8').read()\n",
        "    #file = open(path, 'r',encoding='windows-1252').read() #encoding='windows-1252'\n",
        "    my_dict = xmltodict.parse(file)\n",
        "    my_dict = json.loads(json.dumps(my_dict))\n",
        "    try:\n",
        "        title= my_dict['collection']['document']['passage'][0]['text']\n",
        "    except:\n",
        "        try:\n",
        "            title = my_dict['collection']['document']['passage']['text']\n",
        "        except:\n",
        "            title=''\n",
        "\n",
        "    try:\n",
        "        abstract=my_dict['collection']['document']['passage'][1]['text']\n",
        "\n",
        "    except:\n",
        "        abstract=''\n",
        "\n",
        "    passage= my_dict['collection']['document']['passage']\n",
        "    id=my_dict['collection']['document']['id']\n",
        "\n",
        "    text=title+' '+abstract\n",
        "\n",
        "    return text,passage,id\n",
        "\n",
        "  def get_annotation(self,edit_annotation=False):\n",
        "      passage_list=[]\n",
        "      _,passages,_= self.get_text()\n",
        "      try:\n",
        "          if isinstance(passages,list):\n",
        "              passage_list = passages\n",
        "          elif isinstance(passages,dict):\n",
        "              passage_list = [passages]\n",
        "      except Exception as e:\n",
        "          print(e)\n",
        "\n",
        "      annodation_dic={}\n",
        "      annotation_list=[]\n",
        "\n",
        "      if passage_list!=[]:\n",
        "        annotations=[]\n",
        "        for p in passage_list:\n",
        "            try:\n",
        "                annotations = p['annotation']\n",
        "            except Exception as e:\n",
        "                #print(\">>>>>> error:\",e,'passage:',p)\n",
        "                pass\n",
        "\n",
        "            anno_list=[]\n",
        "            try:\n",
        "                if isinstance(annotations, list):\n",
        "                    anno_list = annotations\n",
        "                elif isinstance(annotations, dict):\n",
        "                    anno_list = [annotations]\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "                # raise ValidationError(_(str(e)))\n",
        "            for i in anno_list:\n",
        "                annotation_list.append(i)\n",
        "\n",
        "      if annotation_list!=[]:\n",
        "        for anno in annotation_list:\n",
        "            annotation_id = anno['@id']\n",
        "            location_stat = anno['location']['@offset']\n",
        "            location_end = int(anno['location']['@offset']) + int(anno['location']['@length'])\n",
        "            location_length = anno['location']['@length']\n",
        "            type = 'None'\n",
        "            identifier = 'None'\n",
        "            annotator = 'None'\n",
        "            txt=anno['text']\n",
        "            for j in anno['infon']:\n",
        "                try:\n",
        "                  if j['@key'] == 'type':\n",
        "                      type = j['#text']\n",
        "                except:\n",
        "                  pass\n",
        "                try:\n",
        "                  if j['@key'] == 'identifier' and '#text' in j.keys():\n",
        "                      identifier = j['#text']\n",
        "                except:\n",
        "                  pass\n",
        "                try:\n",
        "                  if j['@key'] == 'annotator':\n",
        "                      annotator = j['#text']\n",
        "                except:\n",
        "                  pass\n",
        "\n",
        "            if identifier!= None and identifier in interested_tags2:\n",
        "                   type=identifier\n",
        "\n",
        "            if edit_annotation:\n",
        "                if type in interested_tags2:\n",
        "                    annodation_dic[annotation_id] = {'type': type, 'identifier': identifier, 'annotator': annotator,\n",
        "                                                     'start': location_stat,\n",
        "                                                     'end': location_end, 'length': location_length, 'txt': txt}\n",
        "            else:\n",
        "                #if type in interested_tags2:\n",
        "                if type !='None':\n",
        "                  annodation_dic[annotation_id] = {'type': type, 'identifier': identifier, 'annotator': annotator,\n",
        "                                                     'start': location_stat,\n",
        "                                                     'end': location_end, 'length': location_length, 'txt': txt}\n",
        "      return annodation_dic\n",
        "\n",
        "  def get_relation(self, include_anno_type=False,select_annotator=True,annotator=SELECTED_ANNOTATOR[0]):\n",
        "      _,passages,id= self.get_text()\n",
        "      annotation_dict=self.get_annotation()\n",
        "      passage_list=[]\n",
        "      try:\n",
        "          if isinstance(passages,list):\n",
        "            passage_list = passages\n",
        "          elif isinstance(passages,dict):\n",
        "            passage_list = [passages]\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "      relation_dic=defaultdict(dict)\n",
        "      relation_list=[]\n",
        "      all_relation_list_include_anno=[]\n",
        "      all_relation_list=[]\n",
        "      relation_dic={}\n",
        "\n",
        "      if passage_list!=[]:\n",
        "          annotations=[]\n",
        "          for p in passage_list:\n",
        "              try:\n",
        "                  annotations = p['relation']\n",
        "              except Exception as e:\n",
        "                #print(\">>>>>> error:\",e,'passage:',p)\n",
        "                  pass\n",
        "\n",
        "              anno_list=[]\n",
        "              try:\n",
        "                  if isinstance(annotations, list):\n",
        "                    anno_list = annotations\n",
        "                  elif isinstance(annotations, dict):\n",
        "                    anno_list = [annotations]\n",
        "              except Exception as e:\n",
        "                print(e)\n",
        "                # raise ValidationError(_(str(e)))\n",
        "              for i in anno_list:\n",
        "                relation_list.append(i)\n",
        "\n",
        "      if relation_list!=[]:\n",
        "          #print(\"EXTRACTING relationships\")\n",
        "          relation_dic[id]={}\n",
        "          for rela in relation_list:\n",
        "            #print(\" rela:\", rela)\n",
        "            relation_id=rela['@id']\n",
        "            rela_annotator='None'\n",
        "            relation_dic[id][relation_id]=[]\n",
        "            rela_object=[]\n",
        "            rela_subject=[]\n",
        "\n",
        "            for j in rela['infon']:\n",
        "              if j['@key']=='type':\n",
        "                rela_type=j['#text']\n",
        "              if j['@key']=='annotator':\n",
        "                rela_annotator=j['#text']\n",
        "\n",
        "            if select_annotator:\n",
        "              if rela_annotator == annotator:\n",
        "                rela_subject,rela_object=self.CombineRelaSubObj(rela,annotation_dict)\n",
        "              else:\n",
        "                pass\n",
        "\n",
        "            if len(rela_object)>0 and len(rela_object)>0:\n",
        "              for s in rela_subject:\n",
        "                for o in rela_object:\n",
        "                  relation_dic[id][relation_id].append({'relation':rela_type,'subject':s,'object':o})\n",
        "                  all_relation_list.append([rela_type,s,o])\n",
        "                  if include_anno_type:\n",
        "                    try:\n",
        "                      s_type=annotation_dict[s]['type']\n",
        "                      o_type=annotation_dict[o]['type']\n",
        "                    except:\n",
        "                      print(\"please check if you include the annotation_dict\")\n",
        "                    all_relation_list_include_anno.append([rela_type,s,o,s_type,o_type])\n",
        "\n",
        "      return relation_dic,all_relation_list,all_relation_list_include_anno\n",
        "\n",
        "  def CombineRelaSubObj(self,rela,annotation_dict):\n",
        "    rela_object=[]\n",
        "    rela_subject=[]\n",
        "    for n in rela['node']:\n",
        "      try:\n",
        "        if n['@role']=='object':\n",
        "          rela_object.append(n['@refid'])\n",
        "      except:\n",
        "        pass\n",
        "      try:\n",
        "        if n['@role']=='subject':\n",
        "          rela_subject.append(n['@refid'])\n",
        "      except:\n",
        "        pass\n",
        "    return rela_subject,rela_object"
      ],
      "metadata": {
        "id": "fbi-T6D2fS5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import sent_tokenize\n",
        "import re\n",
        "\n",
        "# --- Subject & object markup ---\n",
        "SUB_START_CHAR = \"[\"\n",
        "SUB_END_CHAR = \"]\"\n",
        "OBJ_START_CHAR = \"{\"\n",
        "OBJ_END_CHAR = \"}\"\n",
        "\n",
        "class AbstractProcessing:\n",
        "  def __init__(self, file_path,annotator):\n",
        "    self.file_path=file_path\n",
        "    self.annotator=annotator\n",
        "\n",
        "\n",
        "  def extractor(self):\n",
        "    extractor=AnnotationsExtraction(self.file_path)\n",
        "    text,_,id=extractor.get_text()\n",
        "    annodation_dic=extractor.get_annotation()\n",
        "    relation_dic,_,_=extractor.get_relation(annotator=self.annotator)\n",
        "\n",
        "    return id,text,annodation_dic,relation_dic\n",
        "\n",
        "  def SentToken(self):\n",
        "    id,text,_,_=self.extractor()\n",
        "    splited_text=sent_tokenize(text)\n",
        "    #Spans = list(pt().span_tokenize(text))\n",
        "    SentsSpan=[]\n",
        "\n",
        "    #total_len=0\n",
        "    sent_start=0\n",
        "    sent_end=0\n",
        "    sent_len=0\n",
        "\n",
        "    for sent_id,i in enumerate(splited_text):\n",
        "      if sent_id!=0:\n",
        "        sent_start=sent_end+1\n",
        "      sent_len=len(i)\n",
        "      sent_end=sent_start+sent_len\n",
        "    #total_len+=len(i)\n",
        "      SentsSpan.append([sent_start,sent_end])\n",
        "    return splited_text,SentsSpan\n",
        "\n",
        "  def ProcessingPositiveSent(self):\n",
        "    PositiveSents=defaultdict(dict)\n",
        "    id,text,annodation_dic,relation_dic=self.extractor()\n",
        "    splited_text,SentsSpan=self.SentToken()\n",
        "\n",
        "    re_id=0\n",
        "    if relation_dic!={}:\n",
        "      for re_list_id in relation_dic[id]:\n",
        "        for r in relation_dic[id][re_list_id]:\n",
        "          subject_id=r['subject']\n",
        "          object_id=r['object']\n",
        "          label=r['relation']\n",
        "          #print(r)\n",
        "          subject_anno=annodation_dic[subject_id]\n",
        "          object_anno=annodation_dic[object_id]\n",
        "          #print(subject_anno,object_anno)\n",
        "\n",
        "          for sent_id,sent_span in enumerate(SentsSpan):\n",
        "            if int(subject_anno['start'])>=sent_span[0] and int(subject_anno['end'])<=sent_span[1] and\\\n",
        "              int(object_anno['start'])>=sent_span[0] and int(object_anno['end'])<=sent_span[1]:\n",
        "              PositiveSents[id][re_list_id]=[]\n",
        "              try:\n",
        "                new_sent=str(splited_text[sent_id])\n",
        "                new_sent=re.split(subject_anno['txt'],new_sent)\n",
        "                new_sent=new_sent[0]+SUB_START_CHAR+subject_anno['txt']+SUB_END_CHAR+new_sent[1]\n",
        "                new_sent=re.split(object_anno['txt'],new_sent)\n",
        "                print(new_sent,object_anno['txt'],object_anno['start'],object_anno['end'],sent_span)\n",
        "                print(splited_text[sent_id])\n",
        "                new_sent=new_sent[0]+OBJ_START_CHAR+object_anno['txt']+OBJ_END_CHAR+new_sent[1]\n",
        "                PositiveSents[id][re_list_id].append({'sentence':new_sent,'label':label,'subject':subject_anno,'object':object_anno})\n",
        "                re_id+=1\n",
        "              except:\n",
        "                print(id,new_sent,object_anno['txt'],subject_anno['txt'])\n",
        "                new_sent=str(splited_text[sent_id])\n",
        "                PositiveSents[id][re_list_id].append({'sentence':new_sent,'label':label,'subject':subject_anno,'object':object_anno})\n",
        "                re_id+=1\n",
        "\n",
        "    #print(PositiveSents)\n",
        "\n",
        "    return id,PositiveSents\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl3BlwU7Do-7",
        "outputId": "c57ae7bc-c529-44ba-a686-b81db3efdd2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CalculateAggrement(ABC):\n",
        "  def __init__(self, annotation1,annotation2,restrict=False):\n",
        "    self.annotation1=annotation1,\n",
        "    self.annotation2=annotation2,\n",
        "    self.restrict=restrict\n",
        "\n",
        "  def compare_list(self,a,b):\n",
        "    if_same=0\n",
        "    for i in a:\n",
        "        if i in b:\n",
        "            if_same=1\n",
        "        break\n",
        "    return if_same\n",
        "\n",
        "  def if_same_entity(self, an1, an2):\n",
        "    \"\"\"\n",
        "    :param an1, an2: annotation by first and second anotator, an=[type,start,end]\n",
        "    :param restrict: if yes, only if the type, start, and end of an1 and an2 be the same,\n",
        "    will consider an1 and an2 as the same annotation\n",
        "    :return: weather if an1 and an2 the same annotation\n",
        "    \"\"\"\n",
        "    if_same = 0\n",
        "\n",
        "    if self.restrict:\n",
        "        if an1==an2:\n",
        "            if_same=1\n",
        "    else:\n",
        "        type1=an1[0]\n",
        "        type2=an2[0]\n",
        "\n",
        "        start1=an1[1]\n",
        "        start2=an2[1]\n",
        "\n",
        "        end1=an1[2]\n",
        "        end2=an2[2]\n",
        "\n",
        "        duration1 = [i for i in range(int(start1), int(end1) + 1)]\n",
        "        duration2 = [i for i in range(int(start2), int(end2) + 1)]\n",
        "\n",
        "        if type1 == type2:\n",
        "            if_same=self.compare_list(duration1,duration2)\n",
        "\n",
        "    return if_same\n",
        "\n",
        "  def if_same_relation(self,rela1,rela2):\n",
        "    #print(rela1)\n",
        "    if_same=False\n",
        "    subject1=rela1['subject']\n",
        "    subject2=rela2['subject']\n",
        "\n",
        "    object1=rela1['object']\n",
        "    object2=rela2['object']\n",
        "\n",
        "    sunject1_pos=[subject1['type'],subject1['start'],subject1['end']]\n",
        "    subject2_pos=[subject2['type'],subject2['start'],subject2['end']]\n",
        "\n",
        "    if self.if_same_entity(sunject1_pos,subject2_pos):\n",
        "      object1_pos=[object1['type'],object1['start'],object1['end']]\n",
        "      object2_pos=[object2['type'],object2['start'],object2['end']]\n",
        "      if self.if_same_entity(object1_pos,object2_pos):\n",
        "        if rela1['label']==rela2['label']:\n",
        "          if_same=True\n",
        "\n",
        "    return if_same\n",
        "\n",
        "  def cal_aggrement(self):\n",
        "    \"\"\"Computes Cohen kappa for pair-wise annotators.\n",
        "\n",
        "                 Pr(a) - Pr(e)\n",
        "    Cohen's 𝜅 = ---------------\n",
        "                   1 - Pr(e)\n",
        "\n",
        "    Where...\n",
        "        Pr(a) = the percentage of observed agreement\n",
        "        Pr(e) = the percentage of expected agreement.\n",
        "\n",
        "    :param ann1: relation annotations provided by first annotator\n",
        "    :type ann1: list\n",
        "    :param ann2: relation annotations provided by second annotator\n",
        "    :type ann2: list\n",
        "    :rtype: float\n",
        "    :return: Cohen kappa statistic\n",
        "    \"\"\"\n",
        "    annotation1=[]\n",
        "\n",
        "    for an1 in self.annotation1:\n",
        "      if len(an1)!=0:\n",
        "        for r1 in an1:\n",
        "          annotation1.append(r1)\n",
        "\n",
        "    annotation2=[]\n",
        "\n",
        "    for an2 in self.annotation2:\n",
        "      if len(an1)!=0:\n",
        "        for r2 in an2:\n",
        "          annotation1.append(r2)\n",
        "\n",
        "    count = 0\n",
        "    for an1 in self.annotation1:\n",
        "        for an2 in self.annotation2:\n",
        "          if len(an1)!=0 and len(an2)!=0:\n",
        "            print(\"---------\")\n",
        "            print(\"an1:\",len(an1),an1)\n",
        "            print(\"an2:\",len(an2),an2)\n",
        "            for r1 in an1:\n",
        "              for r2 in an2:\n",
        "                if self.if_same_relation(r1,r2):\n",
        "                  count += 1\n",
        "    A = count / (len(self.annotation1)+1e-5)  # observed agreement A (Po)\n",
        "\n",
        "    #for i in self.annotation1:\n",
        "      #print(i)\n",
        "    try:\n",
        "        #annotation1 =[i[0] for i in  self.annotation1]\n",
        "        type_list1=[i['label'] for i in annotation1]\n",
        "        #annotation2 =[i[0] for i in  self.annotation2]\n",
        "        type_list2=[i['label'] for i in annotation2]\n",
        "        uniq = set(type_list1 + type_list2)\n",
        "    except:\n",
        "        #annotation1 =[i[0] for i in  self.annotation1]\n",
        "        type_list1=[i['label'] for i in annotation1]\n",
        "        type_list2=['None']\n",
        "        uniq=set(type_list1)\n",
        "\n",
        "    E = 0  # expected agreement E (Pe)\n",
        "    for item in uniq:\n",
        "        cnt1 = list(type_list1).count(item)\n",
        "        cnt2 = list(type_list2).count(item)\n",
        "        count = ((cnt1 / (len(type_list1)+1e-5)) * (cnt2 / (len(type_list2)+1e-5)))\n",
        "        E += count\n",
        "\n",
        "    if len(annotation1)==0 and len(annotation2)==0:\n",
        "      print(annotation1)\n",
        "      print(annotation2)\n",
        "      return 1\n",
        "\n",
        "    else:\n",
        "      return round((A - E) / (1 - E + 1e-5), 4)"
      ],
      "metadata": {
        "id": "nb22iAg2mqHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "anno1=[]\n",
        "anno2=[]\n",
        "\n",
        "files=os.listdir(DIR_PATH)\n",
        "\n",
        "for f in files:\n",
        "  file_path=os.path.join(DIR_PATH,f)\n",
        "  extractor=AnnotationsExtraction(file_path)\n",
        "  processor1=AbstractProcessing(file_path,SELECTED_ANNOTATOR[1])\n",
        "  processor2=AbstractProcessing(file_path,SELECTED_ANNOTATOR[0])\n",
        "  text,passage,id=extractor.get_text()\n",
        "  if id in SELECT_ABSTRACTS:\n",
        "    #relation_dic2,all_relation_list,all_relation_list_include_anno=extractor.get_relation(annotator=SELECTED_ANNOTATOR[0])\n",
        "    #relation_dic1,all_relation_list,all_relation_list_include_anno=extractor.get_relation(annotator=SELECTED_ANNOTATOR[1])\n",
        "    _,relation_dic2=processor2.ProcessingPositiveSent()\n",
        "    _,relation_dic1=processor1.ProcessingPositiveSent()\n",
        "    anno2.append(relation_dic2)\n",
        "    anno1.append(relation_dic1)"
      ],
      "metadata": {
        "id": "KjNILfz3jola"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_score=0\n",
        "num=0\n",
        "\n",
        "for a1 in anno1[1:]:\n",
        "  for a2 in anno2[1:]:\n",
        "    if a1.keys()==a2.keys() and len(a1.keys())!=0:\n",
        "      relation1_list=[]\n",
        "      relation2_list=[]\n",
        "\n",
        "      for absract_id in a1.keys():\n",
        "       for relatoion_id in a1[absract_id].keys():\n",
        "         for r in a1[absract_id][relatoion_id]:\n",
        "           if len(r)!=0:\n",
        "            relation1_list.append(r)\n",
        "\n",
        "      for absract_id in a2.keys():\n",
        "       for relatoion_id in a2[absract_id].keys():\n",
        "         for r in a2[absract_id][relatoion_id]:\n",
        "           if len(r)!=0:\n",
        "            relation2_list.append(r)\n",
        "\n",
        "      print(\"\\n\",\"----------------calculate abstract: \",absract_id,\"----------------\")\n",
        "      #print(len(relation1_list),relation1_list)\n",
        "      Calculator=CalculateAggrement(relation1_list,relation2_list)\n",
        "      aggrement_score=Calculator.cal_aggrement()\n",
        "      total_score+=aggrement_score\n",
        "      num+=1\n",
        "      print(\"aggrement_score:\",aggrement_score)\n",
        "    elif a1.keys()==a2.keys() and len(a1.keys())==0 and len(a2.keys())==0:\n",
        "      aggrement_score=1\n",
        "      total_score+=aggrement_score\n",
        "      num+=1\n",
        "\n",
        "\n",
        "print(\"\\n\",\"average aggrement score:\",total_score/num)\n"
      ],
      "metadata": {
        "id": "YMuWnjEyqBmX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8649c2ad-6de3-42d0-de3a-44ff693688f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ----------------calculate abstract:  12828853 ----------------\n",
            "---------\n",
            "an1: 3 [{'sentence': 'CONCLUSION: Attenuation of {ROS} production by neutrophils may play a role in the effects of [LLLT] in the treatment of inflammatory tissues.', 'label': 'ASSOCIATED_WITH', 'subject': {'type': 'Energy_therapies', 'identifier': 'None', 'annotator': 'Huixue', 'start': '1152', 'end': 1156, 'length': '4', 'txt': 'LLLT'}, 'object': {'type': 'molecular', 'identifier': 'None', 'annotator': 'Huixue', 'start': '1088', 'end': 1091, 'length': '3', 'txt': 'ROS'}}, {'sentence': 'There is a possible usage of [LLLT] to improve {wound healing} in smokers.', 'label': 'AFFECTS', 'subject': {'type': 'Energy_therapies', 'identifier': 'None', 'annotator': 'Huixue', 'start': '1228', 'end': 1232, 'length': '4', 'txt': 'LLLT'}, 'object': {'type': 'sign_symptom', 'identifier': 'None', 'annotator': 'Huixue', 'start': '1244', 'end': 1257, 'length': '13', 'txt': 'wound healing'}}, {'sentence': 'BACKGROUND DATA: [LLLT] is an effective therapeutic modality for {inflammatory} conditions.', 'label': 'TREATS', 'subject': {'type': 'Energy_therapies', 'identifier': 'None', 'annotator': 'Huixue', 'start': '279', 'end': 283, 'length': '4', 'txt': 'LLLT'}, 'object': {'type': 'sign_symptom', 'identifier': 'None', 'annotator': 'Huixue', 'start': '325', 'end': 337, 'length': '12', 'txt': 'inflammatory'}}]\n",
            "an2: 1 [{'sentence': 'CONCLUSION: Attenuation of {ROS} production by neutrophils may play a role in the effects of [LLLT] in the treatment of inflammatory tissues.', 'label': 'ASSOCIATED_WITH', 'subject': {'type': 'Energy_therapies', 'identifier': 'None', 'annotator': 'Nathan', 'start': '1152', 'end': 1156, 'length': '4', 'txt': 'LLLT'}, 'object': {'type': 'molecular', 'identifier': 'None', 'annotator': 'Nathan', 'start': '1088', 'end': 1091, 'length': '3', 'txt': 'ROS'}}]\n",
            "aggrement_score: 1.0\n",
            "\n",
            " ----------------calculate abstract:  15039508 ----------------\n",
            "---------\n",
            "an1: 3 [{'sentence': 'Treatment with [hypnotherapy] reduces the sensory and motor component of the gastrocolonic response in {irritable bowel syndrome}.', 'label': 'TREATS', 'subject': {'type': 'Mindbody_therapies', 'identifier': 'None', 'annotator': 'Huixue', 'start': '15', 'end': 27, 'length': '12', 'txt': 'hypnotherapy'}, 'object': {'type': 'sign_symptom', 'identifier': 'None', 'annotator': 'Huixue', 'start': '101', 'end': 125, 'length': '24', 'txt': 'irritable bowel syndrome'}}, {'sentence': 'CONCLUSION: [Hypnotherapy] reduces the {sensory and motor component of the gastrocolonic response} in patients with irritable bowel syndrome.', 'label': 'TREATS', 'subject': {'type': 'Mindbody_therapies', 'identifier': 'None', 'annotator': 'Huixue', 'start': '1851', 'end': 1863, 'length': '12', 'txt': 'Hypnotherapy'}, 'object': {'type': 'sign_symptom', 'identifier': 'None', 'annotator': 'Huixue', 'start': '1876', 'end': 1933, 'length': '57', 'txt': 'sensory and motor component of the gastrocolonic response'}}, {'sentence': 'Controls reduced their thresholds after duodenal lipids for gas (22 +/- 1.7 mm Hg vs. 16 +/- 1.6 mm Hg, p <.01), discomfort (29 +/- 2.9 mm Hg vs. 22 +/- 2.6 mm Hg, p <.01), and {pain} (33 +/- 2.7 mm Hg vs. 26 +/- 3.3 mm Hg, p <.01), whereas the [hypnotherapy] group reduced their thresholds after lipids only for ', 'label': 'TREATS', 'subject': {'type': 'Mindbody_therapies', 'identifier': 'None', 'annotator': 'Huixue', 'start': '1304', 'end': 1316, 'length': '12', 'txt': 'hypnotherapy'}, 'object': {'type': 'chronic_pain_snsy', 'identifier': 'None', 'annotator': 'Huixue', 'start': '1370', 'end': 1374, 'length': '4', 'txt': 'pain'}}]\n",
            "an2: 3 [{'sentence': 'Treatment with [hypnotherapy] reduces the sensory and motor component of the gastrocolonic response in {irritable bowel syndrome}.', 'label': 'TREATS', 'subject': {'type': 'Mindbody_therapies', 'identifier': 'None', 'annotator': 'Nathan', 'start': '15', 'end': 27, 'length': '12', 'txt': 'hypnotherapy'}, 'object': {'type': 'sign_symptom', 'identifier': 'None', 'annotator': 'Nathan', 'start': '101', 'end': 125, 'length': '24', 'txt': 'irritable bowel syndrome'}}, {'sentence': 'CONCLUSION: [Hypnotherapy] reduces the sensory and motor component of the gastrocolonic response in patients with {irritable bowel syndrome}.', 'label': 'TREATS', 'subject': {'type': 'Mindbody_therapies', 'identifier': 'None', 'annotator': 'Nathan', 'start': '1851', 'end': 1863, 'length': '12', 'txt': 'Hypnotherapy'}, 'object': {'type': 'sign_symptom', 'identifier': 'None', 'annotator': 'Nathan', 'start': '1951', 'end': 1975, 'length': '24', 'txt': 'irritable bowel syndrome'}}, {'sentence': 'These effects may be involved in the clinical efficacy of [hypnotherapy] in {IBS}.', 'label': 'TREATS', 'subject': {'type': 'Mindbody_therapies', 'identifier': 'None', 'annotator': 'Nathan', 'start': '2035', 'end': 2047, 'length': '12', 'txt': 'hypnotherapy'}, 'object': {'type': 'sign_symptom', 'identifier': 'None', 'annotator': 'Nathan', 'start': '2051', 'end': 2054, 'length': '3', 'txt': 'IBS'}}]\n",
            "aggrement_score: 1.0\n",
            "\n",
            " ----------------calculate abstract:  12584510 ----------------\n",
            "---------\n",
            "an1: 1 [{'sentence': '[Chiropractic spinal manipulation] may have a positive effect in {pain} reduction and improved function in patients who have NF-1 without spinal instability.', 'label': 'TREATS', 'subject': {'type': 'Manual_bodybased_therapies', 'identifier': 'None', 'annotator': 'Huixue', 'start': '1427', 'end': 1459, 'length': '32', 'txt': 'Chiropractic spinal manipulation'}, 'object': {'type': 'chronic_pain_snsy', 'identifier': 'None', 'annotator': 'Huixue', 'start': '1490', 'end': 1494, 'length': '4', 'txt': 'pain'}}]\n",
            "an2: 1 [{'sentence': 'Chiropractic [spinal manipulation] may have a positive effect in pain reduction and improved function in patients who have {NF-1} without spinal instability.', 'label': 'TREATS', 'subject': {'type': 'Manual_bodybased_therapies', 'identifier': 'None', 'annotator': 'Nathan', 'start': '1440', 'end': 1459, 'length': '19', 'txt': 'spinal manipulation'}, 'object': {'type': 'sign_symptom', 'identifier': 'None', 'annotator': 'Nathan', 'start': '1548', 'end': 1552, 'length': '4', 'txt': 'NF-1'}}]\n",
            "aggrement_score: 0.0\n",
            "\n",
            " ----------------calculate abstract:  12799612 ----------------\n",
            "---------\n",
            "an1: 3 [{'sentence': 'LPO was reduced significantly and reduced {glutathione} levels showed significant improvement after the [exercise-conditioning programme].', 'label': 'INHIBITS', 'subject': {'type': 'Manual_bodybased_therapies', 'identifier': 'None', 'annotator': 'Huixue', 'start': '968', 'end': 999, 'length': '31', 'txt': 'exercise-conditioning programme'}, 'object': {'type': 'molecular', 'identifier': 'None', 'annotator': 'Huixue', 'start': '908', 'end': 919, 'length': '11', 'txt': 'glutathione'}}, {'sentence': 'In conclusion, regular [water-based exercise] has beneficial effects on the cardiorespiratory, renal functional parameters and oxidative stress status in patients with moderate renal failure, and can be used in the complex rehabilitation of {chronic renal failure} patients, together with blood pressure control, dietary consultation, encouragement and education to prevent physical worsening and to postpone cardiovascular and renal atherosclerotic complications.', 'label': 'TREATS', 'subject': {'type': 'Manual_bodybased_therapies', 'identifier': 'None', 'annotator': 'Huixue', 'start': '1119', 'end': 1139, 'length': '20', 'txt': 'water-based exercise'}, 'object': {'type': 'sign_symptom', 'identifier': 'None', 'annotator': 'Huixue', 'start': '1335', 'end': 1356, 'length': '21', 'txt': 'chronic renal failure'}}, {'sentence': 'The results showed that in the [exercise group] all {cardiorespiratory functional parameters} improved and resting blood pressure lowered significantly.', 'label': 'TREATS', 'subject': {'type': 'Manual_bodybased_therapies', 'identifier': 'None', 'annotator': 'Huixue', 'start': '500', 'end': 514, 'length': '14', 'txt': 'exercise group'}, 'object': {'type': 'sign_symptom', 'identifier': 'None', 'annotator': 'Huixue', 'start': '519', 'end': 558, 'length': '39', 'txt': 'cardiorespiratory functional parameters'}}]\n",
            "an2: 1 [{'sentence': 'In conclusion, [regular water-based exercise] has beneficial effects on the cardiorespiratory, renal functional parameters and oxidative stress status in patients with moderate renal failure, and can be used in the complex rehabilitation of {chronic renal failure} patients, together with blood pressure control, dietary consultation, encouragement and education to prevent physical worsening and to postpone cardiovascular and renal atherosclerotic complications.', 'label': 'TREATS', 'subject': {'type': 'Manual_bodybased_therapies', 'identifier': 'None', 'annotator': 'Nathan', 'start': '1111', 'end': 1139, 'length': '28', 'txt': 'regular water-based exercise'}, 'object': {'type': 'sign_symptom', 'identifier': 'None', 'annotator': 'Nathan', 'start': '1335', 'end': 1356, 'length': '21', 'txt': 'chronic renal failure'}}]\n",
            "aggrement_score: 1.0\n",
            "\n",
            " average aggrement score: 0.9964788732394366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "anno2"
      ],
      "metadata": {
        "id": "PGAZenCZnWdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anno1"
      ],
      "metadata": {
        "id": "uZrxAK0lnr89"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}